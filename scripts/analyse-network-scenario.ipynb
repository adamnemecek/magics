{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append('scripts')\n",
    "\n",
    "import re\n",
    "import json\n",
    "import argparse\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "import collections\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from matplotlib.font_manager import FontProperties\n",
    "import matplotlib.font_manager as fm\n",
    "from matplotlib.patches import FancyBboxPatch\n",
    "from matplotlib.patches import PathPatch\n",
    "from matplotlib.path import get_path_collection_extents\n",
    "import seaborn as sns\n",
    "\n",
    "from rich import print, pretty\n",
    "from typing import  Iterable\n",
    "import pretty_errors\n",
    "from catppuccin import PALETTE\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "# import .scripts.ldj\n",
    "from ldj import ldj\n",
    "from utils import *\n",
    "\n",
    "pretty.install()\n",
    "\n",
    "RESULTS_DIRS = [\n",
    "    Path('./experiments/varying-network-connectivity-lm-3-tk-13.33-sd-2.2'),\n",
    "    # Path('./experiments/varying-network-connectivity-lm-3-th-13-sd-2.5'),\n",
    "    Path('./experiments/varying-network-connectivity-gbpplanner'),\n",
    "]\n",
    "\n",
    "for RESULTS_DIR in RESULTS_DIRS:\n",
    "    assert RESULTS_DIR.is_dir() and RESULTS_DIR.exists()\n",
    "\n",
    "# RESULTS_DIR = Path('./experiments/circle-experiment-lm-3-th-5')\n",
    "# assert RESULTS_DIR.is_dir() and RESULTS_DIR.exists()\n",
    "\n",
    "flavor = PALETTE.latte.colors\n",
    "# num-robots-10-seed-0.json\n",
    "RE = re.compile(r\"comms-radius-(\\d+)-seed-(\\d+).json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use LaTeX for text with matplotlib\n",
    "sns.set_style(\"darkgrid\")\n",
    "# set background color of sns darkgrid to flavor.base.hex\n",
    "plt.rcParams['axes.facecolor'] = flavor.base.hex\n",
    "# set font color to flavor.text.hex\n",
    "plt.rcParams['text.color'] = flavor.text.hex\n",
    "\n",
    "font_dirs = [\"./scripts/fonts/\"]\n",
    "# go through all fonts in the font directory and add them\n",
    "for font_dir in font_dirs:\n",
    "    for font in os.listdir(font_dir):\n",
    "        fm.fontManager.addfont(f\"{font_dir}/{font}\")\n",
    "\n",
    "prop_jbm = fm.FontProperties(fname='./scripts/fonts/JetBrainsMonoNerdFontMono-Regular.ttf')\n",
    "prop = fm.FontProperties(fname='./scripts/fonts/STIXTwoText-VariableFont_wght.ttf')\n",
    "\n",
    "plt.rcParams.update({\n",
    "    # \"text.usetex\": True,\n",
    "    \"font.family\": prop.get_name(),\n",
    "    # \"font.family\": \"stix\",\n",
    "    # \"font.sans-serif\": prop.get_name(),\n",
    "    \"mathtext.fontset\": \"stix\",\n",
    "    # \"text.latex.preamble\": r\"\\usepackage{fontenc}\\usepackage{fontspec}\\setmainfont{JetBrainsMonoNerdFontMono-Regular}\",\n",
    "})\n",
    "\n",
    "print(prop.get_name())\n",
    "\n",
    "colors = [(flavor.lavender.hex, 1.0), (flavor.yellow.hex, 0.3), (flavor.peach.hex, 0.3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def flatten(lst: Iterable) -> list:\n",
    "    return list(itertools.chain.from_iterable(lst))\n",
    "\n",
    "def process_file_(file):\n",
    "    # print(f\"Processing {file}\")\n",
    "    match = RE.match(file.name)\n",
    "    assert match is not None\n",
    "    comms_radius = int(match.group(1))\n",
    "    seed = int(match.group(2))\n",
    "\n",
    "    with open(file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    distance_travelled_of_each_robot: list[float] = []\n",
    "    ldj_of_each_robot: list[float] = []\n",
    "    time_to_completion_of_each_robot: list[float] = []\n",
    "\n",
    "    for _, robot_data in data['robots'].items():\n",
    "        positions = np.array(robot_data['positions'])\n",
    "        \n",
    "        distance_travelled = np.sum(np.linalg.norm(np.diff(positions, axis=0), axis=1))\n",
    "        distance_travelled_of_each_robot.append(distance_travelled)\n",
    "        mission = robot_data['mission']\n",
    "        \n",
    "        t_start: float = mission['started_at']\n",
    "        t_final: float = mission['finished_at'] if mission['finished_at'] else mission['duration'] + t_start\n",
    "        time_to_completion_of_each_robot.append(t_final - t_start)\n",
    "\n",
    "        # timestamps: np.ndarray = np.array([measurement['timestamp'] for measurement in robot_data['velocities']])\n",
    "        timestamps: np.ndarray = np.array([t_start + 0.1 * i for i in range(len(robot_data['velocities']))])\n",
    "        velocities3d_bevy: np.ndarray = np.array([measurement['velocity'] if isinstance(measurement, dict) else measurement for measurement in robot_data['velocities']])\n",
    "        # if velocities3d_bevy.shape[1] != 3: print(velocities3d_bevy.shape)\n",
    "        velocities = velocities3d_bevy[:, [0, 2]] if velocities3d_bevy.shape[1] == 3 else velocities3d_bevy\n",
    "\n",
    "        # metric = ldj(velocities, timestamps)\n",
    "        metric = ldj(velocities, timestamps)\n",
    "        ldj_of_each_robot.append(metric)\n",
    "\n",
    "    # makespan: float = data['makespan']\n",
    "    makespan: float = max(time_to_completion_of_each_robot)\n",
    "    # print(f\"{makespan=}\")\n",
    "    return comms_radius, distance_travelled_of_each_robot, makespan, ldj_of_each_robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[0.1 * i for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = []\n",
    "for RESULTS_DIR in RESULTS_DIRS:\n",
    "    # with ProcessPoolExecutor() as executor:\n",
    "    #     results = executor.map(process_file_, RESULTS_DIR.glob('*.json'))\n",
    "\n",
    "    print(f\"Processing {RESULTS_DIR=}\")\n",
    "\n",
    "    results = [process_file_(file) for file in RESULTS_DIR.glob('*.json')]\n",
    "\n",
    "    # Aggregate results in a single-threaded manner to avoid data\n",
    "    aggregated_data_distance_travelled: dict[int, list[float]] = collections.defaultdict(list)\n",
    "    aggregated_data_makespan: dict[int, list[float]] = collections.defaultdict(list)\n",
    "    aggregated_data_ldj: dict[int, list[float]] = collections.defaultdict(list)\n",
    "\n",
    "    for comms_radius, distance_travelled_for_each_robot, makespan, ldj_for_each_robot in results:\n",
    "        # print(f\"{comms_radius=} {makespan=}\")\n",
    "        aggregated_data_distance_travelled[comms_radius].extend(distance_travelled_for_each_robot)\n",
    "        aggregated_data_makespan[comms_radius].append(makespan)\n",
    "        aggregated_data_ldj[comms_radius].extend(ldj_for_each_robot)\n",
    "\n",
    "    data_distance = [aggregated_data_distance_travelled[key] for key in sorted(aggregated_data_distance_travelled.keys())]\n",
    "    labels_distance = sorted(aggregated_data_distance_travelled.keys())\n",
    "\n",
    "    data_distance_dict = dict(zip(labels_distance, data_distance))\n",
    "\n",
    "    data.append(\n",
    "        {\n",
    "            'distance': data_distance_dict,\n",
    "            # 'labels_distance': labels_distance,\n",
    "            'makespan': aggregated_data_makespan,\n",
    "            'ldj': aggregated_data_ldj\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each comms radius, [20, 40, 60, 80], calculate mean makespan, distance travelled, and ldj\n",
    "\n",
    "for i, d in enumerate(data):\n",
    "\n",
    "    makespan_means = dict([(key, np.mean(d['makespan'][key])) for key in sorted(d['makespan'].keys())])\n",
    "    distance_means = dict([(key, np.mean(d['distance'][key])) for key in sorted(d['distance'].keys())])\n",
    "    ldj_means = dict([(key, np.mean(d['ldj'][key])) for key in sorted(d['ldj'].keys())])\n",
    "\n",
    "    print(f\"{RESULTS_DIRS[i].name}\")\n",
    "    print(f\"{makespan_means=}\")\n",
    "    print(f\"{distance_means=}\")\n",
    "    print(f\"{ldj_means=}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
